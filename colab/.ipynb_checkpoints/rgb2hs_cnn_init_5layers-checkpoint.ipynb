{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_lgePVfXS4PQ",
    "outputId": "bf0f9c6c-b9a0-4167-c48d-a02b55d5ff15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NoNHnY9ZMyr"
   },
   "outputs": [],
   "source": [
    "rgbdir=\"/content/gdrive/My Drive/NTIRE2020_Clean\"\n",
    "hsdir=\"/content/gdrive/My Drive/NTIRE2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "colab_type": "code",
    "id": "bk2WFUcQTolf",
    "outputId": "a5d9ccaf-0ec4-4105-8d0f-6aeb01e2f89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ARAD_HS_0001.mat\n",
      "1 ARAD_HS_0002.mat\n",
      "2 ARAD_HS_0003.mat\n",
      "3 ARAD_HS_0004.mat\n",
      "4 ARAD_HS_0005.mat\n",
      "5 ARAD_HS_0006.mat\n",
      "6 ARAD_HS_0007.mat\n",
      "7 ARAD_HS_0008.mat\n",
      "8 ARAD_HS_0009.mat\n",
      "9 ARAD_HS_0010.mat\n",
      "10 ARAD_HS_0011.mat\n",
      "11 ARAD_HS_0012.mat\n",
      "12 ARAD_HS_0013.mat\n",
      "13 ARAD_HS_0014.mat\n",
      "14 ARAD_HS_0015.mat\n",
      "15 ARAD_HS_0016.mat\n",
      "16 ARAD_HS_0017.mat\n",
      "17 ARAD_HS_0018.mat\n",
      "18 ARAD_HS_0019.mat\n",
      "19 ARAD_HS_0020.mat\n",
      "20 ARAD_HS_0021.mat\n",
      "21 ARAD_HS_0022.mat\n",
      "22 ARAD_HS_0023.mat\n",
      "23 ARAD_HS_0024.mat\n",
      "24 ARAD_HS_0025.mat\n",
      "25 ARAD_HS_0026.mat\n",
      "26 ARAD_HS_0027.mat\n",
      "27 ARAD_HS_0028.mat\n",
      "28 ARAD_HS_0029.mat\n",
      "29 ARAD_HS_0030.mat\n",
      "30 ARAD_HS_0031.mat\n",
      "31 ARAD_HS_0032.mat\n",
      "32 ARAD_HS_0033.mat\n",
      "33 ARAD_HS_0034.mat\n",
      "34 ARAD_HS_0035.mat\n",
      "35 ARAD_HS_0036.mat\n",
      "36 ARAD_HS_0037.mat\n",
      "37 ARAD_HS_0038.mat\n",
      "38 ARAD_HS_0039.mat\n",
      "39 ARAD_HS_0040.mat\n",
      "40 ARAD_HS_0041.mat\n",
      "41 ARAD_HS_0042.mat\n",
      "42 ARAD_HS_0043.mat\n",
      "43 ARAD_HS_0044.mat\n",
      "44 ARAD_HS_0045.mat\n",
      "45 ARAD_HS_0046.mat\n",
      "46 ARAD_HS_0047.mat\n",
      "47 ARAD_HS_0048.mat\n",
      "48 ARAD_HS_0049.mat\n",
      "49 ARAD_HS_0050.mat\n",
      "(50, 482, 512, 31)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "errs=[]\n",
    "# final_numpyData = np.array(0)\n",
    "directory=hsdir\n",
    "final_numpyData=np.array(0)\n",
    "for i,pic in enumerate(sorted(os.listdir(directory))):\n",
    "    if i<50:\n",
    "        try:\n",
    "            x=loadmat(directory+'/'+pic)\n",
    "        except:\n",
    "            errs.append(pic)\n",
    "            continue\n",
    "        matimg=x['cube']\n",
    "        final_numpyData=matimg if i==0 else np.stack([final_numpyData,matimg]) if i==1 else np.concatenate([final_numpyData,np.expand_dims(matimg, axis=0)])\n",
    "        print(i,pic)\n",
    "    else:\n",
    "        break\n",
    "print(final_numpyData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aFSmk0S-VcK2",
    "outputId": "ca8fc179-734e-4e6a-c24a-08af4964e7e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_numpyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LNX7d5CSZCho",
    "outputId": "2529ebf7-d60f-40f7-862d-b5a90ee968ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482, 512, 3)\n",
      "0 ARAD_HS_0001_clean.png\n",
      "(482, 512, 3)\n",
      "1 ARAD_HS_0002_clean.png\n",
      "(482, 512, 3)\n",
      "2 ARAD_HS_0003_clean.png\n",
      "(482, 512, 3)\n",
      "3 ARAD_HS_0004_clean.png\n",
      "(482, 512, 3)\n",
      "4 ARAD_HS_0005_clean.png\n",
      "(482, 512, 3)\n",
      "5 ARAD_HS_0006_clean.png\n",
      "(482, 512, 3)\n",
      "6 ARAD_HS_0007_clean.png\n",
      "(482, 512, 3)\n",
      "7 ARAD_HS_0008_clean.png\n",
      "(482, 512, 3)\n",
      "8 ARAD_HS_0009_clean.png\n",
      "(482, 512, 3)\n",
      "9 ARAD_HS_0010_clean.png\n",
      "(482, 512, 3)\n",
      "10 ARAD_HS_0011_clean.png\n",
      "(482, 512, 3)\n",
      "11 ARAD_HS_0012_clean.png\n",
      "(482, 512, 3)\n",
      "12 ARAD_HS_0013_clean.png\n",
      "(482, 512, 3)\n",
      "13 ARAD_HS_0014_clean.png\n",
      "(482, 512, 3)\n",
      "14 ARAD_HS_0015_clean.png\n",
      "(482, 512, 3)\n",
      "15 ARAD_HS_0016_clean.png\n",
      "(482, 512, 3)\n",
      "16 ARAD_HS_0017_clean.png\n",
      "(482, 512, 3)\n",
      "17 ARAD_HS_0018_clean.png\n",
      "(482, 512, 3)\n",
      "18 ARAD_HS_0019_clean.png\n",
      "(482, 512, 3)\n",
      "19 ARAD_HS_0020_clean.png\n",
      "(482, 512, 3)\n",
      "20 ARAD_HS_0021_clean.png\n",
      "(482, 512, 3)\n",
      "21 ARAD_HS_0022_clean.png\n",
      "(482, 512, 3)\n",
      "22 ARAD_HS_0023_clean.png\n",
      "(482, 512, 3)\n",
      "23 ARAD_HS_0024_clean.png\n",
      "(482, 512, 3)\n",
      "24 ARAD_HS_0025_clean.png\n",
      "(482, 512, 3)\n",
      "25 ARAD_HS_0026_clean.png\n",
      "(482, 512, 3)\n",
      "26 ARAD_HS_0027_clean.png\n",
      "(482, 512, 3)\n",
      "27 ARAD_HS_0028_clean.png\n",
      "(482, 512, 3)\n",
      "28 ARAD_HS_0029_clean.png\n",
      "(482, 512, 3)\n",
      "29 ARAD_HS_0030_clean.png\n",
      "(482, 512, 3)\n",
      "30 ARAD_HS_0031_clean.png\n",
      "(482, 512, 3)\n",
      "31 ARAD_HS_0032_clean.png\n",
      "(482, 512, 3)\n",
      "32 ARAD_HS_0033_clean.png\n",
      "(482, 512, 3)\n",
      "33 ARAD_HS_0034_clean.png\n",
      "(482, 512, 3)\n",
      "34 ARAD_HS_0035_clean.png\n",
      "(482, 512, 3)\n",
      "35 ARAD_HS_0036_clean.png\n",
      "(482, 512, 3)\n",
      "36 ARAD_HS_0037_clean.png\n",
      "(482, 512, 3)\n",
      "37 ARAD_HS_0038_clean.png\n",
      "(482, 512, 3)\n",
      "38 ARAD_HS_0039_clean.png\n",
      "(482, 512, 3)\n",
      "39 ARAD_HS_0040_clean.png\n",
      "(482, 512, 3)\n",
      "40 ARAD_HS_0041_clean.png\n",
      "(482, 512, 3)\n",
      "41 ARAD_HS_0042_clean.png\n",
      "(482, 512, 3)\n",
      "42 ARAD_HS_0043_clean.png\n",
      "(482, 512, 3)\n",
      "43 ARAD_HS_0044_clean.png\n",
      "(482, 512, 3)\n",
      "44 ARAD_HS_0045_clean.png\n",
      "(482, 512, 3)\n",
      "45 ARAD_HS_0046_clean.png\n",
      "(482, 512, 3)\n",
      "46 ARAD_HS_0047_clean.png\n",
      "(482, 512, 3)\n",
      "47 ARAD_HS_0048_clean.png\n",
      "(482, 512, 3)\n",
      "48 ARAD_HS_0049_clean.png\n",
      "(482, 512, 3)\n",
      "49 ARAD_HS_0050_clean.png\n",
      "(50, 482, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "rgb_numpyData=np.array(0)\n",
    "for i,pic in enumerate(sorted(os.listdir(rgbdir))):\n",
    "    # print(i,pic)\n",
    "    # print(os.path.join(directory, pic))\n",
    "    if i<50:\n",
    "        # print('yes')\n",
    "        try:\n",
    "            matimg = cv2.imread(rgbdir+\"/\"+pic)\n",
    "            print(matimg.shape)\n",
    "        except Exception as e:\n",
    "            errs.append(pic)\n",
    "            print(e)\n",
    "            continue\n",
    "        rgb_numpyData=matimg if i==0 else np.stack([rgb_numpyData,matimg]) if i==1 else np.concatenate([rgb_numpyData,np.expand_dims(matimg, axis=0)])\n",
    "        print(i,pic)\n",
    "    else:\n",
    "        break\n",
    "print(rgb_numpyData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "5pYT9GeScw61",
    "outputId": "ac1513aa-c738-4239-b68f-d9d38155f0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data and Ground truth shape................. (40, 482, 512, 3) (40, 482, 512, 31)\n",
      "Validation Split Completed........................... (10, 482, 512, 3) (10, 482, 512, 31)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_data,Y_data=rgb_numpyData,final_numpyData\n",
    "X_train,  X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size=0.2)\t\t\n",
    "\n",
    "print(\"Training data and Ground truth shape.................\",X_train.shape,Y_train.shape)\n",
    "print('Validation Split Completed...........................', X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWHnVyeHc-sm"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import (Input,Activation, Conv2D, Dropout, Convolution2D,UpSampling2D)\n",
    "from keras.layers import (Activation, Conv3D, Dense, Dropout, Flatten,Conv2DTranspose,\n",
    "                  Add,MaxPooling2D,MaxPooling3D, Input, Concatenate,BatchNormalization)\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.losses import mean_absolute_error\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.optimizers import Adam\n",
    "import os, math\n",
    "import matplotlib\n",
    "# matplotlib.use('AGG')\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class model_rgb2hs():\n",
    "\n",
    "    def __init__(self, image_size):\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def Cnn(self):\n",
    "        inp = Input((None, None,3))\n",
    "        C1 = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(inp)\n",
    "        C2 = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(C1) \n",
    "        C3 = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(C2) \n",
    "        C4 = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(C3)\n",
    "        Cout = Conv2D(31, kernel_size=(3,3), padding='same', activation='relu')(C4)\n",
    "        model = Model(inp, Cout)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZ4g0LHpFXxr"
   },
   "outputs": [],
   "source": [
    "epochs=5\n",
    "batch_size=4\n",
    "lr=0.0001\n",
    "\n",
    "initial_epoch=0\n",
    "\n",
    "model_save_dir=\"/content/gdrive/My Drive/Colab Notebooks/RGB2Hyperspectral group 45 cnn/models\"\n",
    "model_name=\"cnn_init_5\"\n",
    "version=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1q3ZIVniHzGt"
   },
   "outputs": [],
   "source": [
    "m=model_rgb2hs(246784)\n",
    "model=m.Cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "OyFfFNk-BkdL",
    "outputId": "572139aa-8869-460e-9546-4a8513079c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 0.9546 - mae: 0.9546 - mse: 6.7127 - val_loss: 0.2474 - val_mae: 0.2474 - val_mse: 0.2938\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 9s 231ms/step - loss: 0.3014 - mae: 0.3014 - mse: 0.3020 - val_loss: 0.1291 - val_mae: 0.1291 - val_mse: 0.0440\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 9s 228ms/step - loss: 0.2124 - mae: 0.2124 - mse: 0.0941 - val_loss: 0.1226 - val_mae: 0.1226 - val_mse: 0.0374\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 9s 227ms/step - loss: 0.2032 - mae: 0.2032 - mse: 0.0862 - val_loss: 0.1212 - val_mae: 0.1212 - val_mse: 0.0362\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 9s 225ms/step - loss: 0.1972 - mae: 0.1972 - mse: 0.0815 - val_loss: 0.1156 - val_mae: 0.1156 - val_mse: 0.0331\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer=Adam(lr=lr), metrics=['mae','mse'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(model_save_dir+'/model_'+str(model_name)+'_'+str(version)+'_{epoch:02d}-{loss:.4f}.h5',monitor='loss',verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=50)\n",
    "csv_logger = keras.callbacks.CSVLogger(model_save_dir + \"/tr_-v\"+str(version)+\".csv\", separator=',', append=True)\n",
    "history = model.fit(x=X_data, y=Y_data, batch_size=batch_size, epochs=epochs, verbose=1, initial_epoch=initial_epoch,\n",
    " \t\t\t\t\tvalidation_split=0.2,callbacks=[checkpoint, csv_logger], shuffle=False)\n",
    "# history = model.fit(x=X_data, y=Y_data, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2, \n",
    "                            # validation_data=(X_val, Y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UGKR_MsDwfZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], 'b', label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss -v'+str(model_name)+str(version))\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(model_save_dir, str(model_name)+'_train_loss_'+str(version)+'_'+str(epochs)+'.png')) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "BCD9ysViHgld",
    "outputId": "65a87cac-9e70-4153-9629-8ea0b6604b2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9546321570873261,\n",
       "  0.3014133498072624,\n",
       "  0.21244409531354905,\n",
       "  0.2032039500772953,\n",
       "  0.19715333133935928],\n",
       " 'mae': [0.9546321, 0.30141336, 0.2124441, 0.20320395, 0.19715333],\n",
       " 'mse': [6.712692, 0.30197474, 0.094057694, 0.08616509, 0.08152997],\n",
       " 'val_loss': [0.24740212857723237,\n",
       "  0.12914455384016038,\n",
       "  0.12261656373739242,\n",
       "  0.12122237235307694,\n",
       "  0.11557181775569916],\n",
       " 'val_mae': [0.2474021315574646,\n",
       "  0.129144549369812,\n",
       "  0.12261656671762466,\n",
       "  0.1212223693728447,\n",
       "  0.11557181924581528],\n",
       " 'val_mse': [0.2937965393066406,\n",
       "  0.04400714859366417,\n",
       "  0.03744694963097572,\n",
       "  0.036231424659490585,\n",
       "  0.033115629106760025]}"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ymutWxLWJeBl",
    "outputId": "7f46958f-9153-4a0a-8618-54bb3c3d283f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(model_save_dir+'/model_'+str(model_name)+'_'+str(version)+'_'+str(epochs)+'.json', \"w+\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(model_save_dir+'/model_'+str(model_name)+'_'+str(version)+'_'+str(epochs)+'.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rgb2hs_cnn_init_5layers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
